<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
	<title>Blog | Esmail Gumaan</title>
    
    <link rel="stylesheet" href="style.5bf229ba612a93f7a45ddc33c771196cc42cd29f90a6a8fe00a7d96b38442d35.css" type="text/css" media="all" />
	<link rel="shortcut icon" href="/favicon.png" type="image/x-icon">
	<link rel="alternate" type="application/rss+xml" href="https://ericmurphy.xyz/blog/index.xml" title="Esmail Gumaan" />
	</head>

<body>

<header class="site-header">
  <nav class="site-nav">
    <a class="logo" href="https://EsmailA.Gumaan/">
      Esmail Gumaan    </a>

    <ul class="menu">
      <li>
        <a href="MediumBlogs.html">Blogs</a>
      </li><li>
        <a href="Projects.html">Projects</a>
      </li><li>
        <a href="index.html">home</a>
      </li><li>
        <!-- <a href="/links">Links</a> -->
      </li><li>
        <a href="contact.html">Contact</a>
      </li><li>
        <!-- <a href="/donate">Donate</a> -->
      </li>
    </ul>

    <ul class="menu menu-social">
      <li>
        <a href="https://github.com/Esmail-ibraheem" target="_blank" rel="noopener noreferrer">
          <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" ><title>GitHub</title><path fill='currentColor' d="M12.001 2C6.47598 2 2.00098 6.475 2.00098 12C2.00098 16.425 4.86348 20.1625 8.83848 21.4875C9.33848 21.575 9.52598 21.275 9.52598 21.0125C9.52598 20.775 9.51348 19.9875 9.51348 19.15C7.00098 19.6125 6.35098 18.5375 6.15098 17.975C6.03848 17.6875 5.55098 16.8 5.12598 16.5625C4.77598 16.375 4.27598 15.9125 5.11348 15.9C5.90098 15.8875 6.46348 16.625 6.65098 16.925C7.55098 18.4375 8.98848 18.0125 9.56348 17.75C9.65098 17.1 9.91348 16.6625 10.201 16.4125C7.97598 16.1625 5.65098 15.3 5.65098 11.475C5.65098 10.3875 6.03848 9.4875 6.67598 8.7875C6.57598 8.5375 6.22598 7.5125 6.77598 6.1375C6.77598 6.1375 7.61348 5.875 9.52598 7.1625C10.326 6.9375 11.176 6.825 12.026 6.825C12.876 6.825 13.726 6.9375 14.526 7.1625C16.4385 5.8625 17.276 6.1375 17.276 6.1375C17.826 7.5125 17.476 8.5375 17.376 8.7875C18.0135 9.4875 18.401 10.375 18.401 11.475C18.401 15.3125 16.0635 16.1625 13.8385 16.4125C14.201 16.725 14.5135 17.325 14.5135 18.2625C14.5135 19.6 14.501 20.675 14.501 21.0125C14.501 21.275 14.6885 21.5875 15.1885 21.4875C19.259 20.1133 21.9999 16.2963 22.001 12C22.001 6.475 17.526 2 12.001 2Z"></path></svg>

        </a>
      </li><li>
        <a href="http://linkedin.com/in/esmail-a-gumaan" target="_blank" rel="noopener noreferrer">
            <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
              <title>LinkedIn</title>
              <path fill="currentColor" d="M20.447 20.452h-3.554v-5.569c0-1.328-.026-3.038-1.855-3.038-1.857 0-2.141 1.45-2.141 2.947v5.66H9.341V9h3.413v1.561h.049c.476-.9 1.636-1.848 3.368-1.848 3.599 0 4.262 2.367 4.262 5.452v6.287h-.001zM5.337 7.433c-1.144 0-2.07-.927-2.07-2.07 0-1.144.927-2.07 2.07-2.07s2.07.926 2.07 2.07c0 1.143-.926 2.07-2.07 2.07zm1.777 13.019H3.561V9h3.553v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.737v20.527C0 23.226.792 24 1.771 24h20.451c.979 0 1.771-.774 1.771-1.736V1.737C23.996.774 23.204 0 22.225 0z"></path>
            </svg>
          </a>
      </li><li>
        <a href="https://medium.com/@Esmail_A.Gumaan/" target="_blank" rel="noopener noreferrer">
            <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
              <title>Medium</title>
              <path fill="currentColor" d="M2.646 3.478c.059-.583-.165-.836-.486-.875H.501v-.088h6.041l4.656 10.2L15.143 2.5h6.051v.088h-1.655c-.318.035-.541.291-.486.875v16.922c-.055.584.168.84.486.875h1.655v.09h-7.925v-.09h1.679c.318-.035.541-.291.486-.875v-13.25L10.062 23.5H9.436L3.19 7.657v10.743c-.088.667.137.935.567.935h1.43v.09H0.097v-.09h1.431c.43 0 .654-.268.567-.935z"/>
            </svg>
          </a>
      </li>
      <li>
        <a href="https://huggingface.co/Esmail-AGumaan" target="_blank" rel="noopener noreferrer">
            <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
              <title>Hugging Face</title>
              <path fill="currentColor" d="M12 0C18.627 0 24 5.373 24 12c0 6.627-5.373 12-12 12S0 18.627 0 12 5.373 0 12 0zm-1.732 5.25C9.345 5.25 8.25 6.345 8.25 7.732c0 .827.358 1.571.932 2.071-1.072.225-2.07.731-2.868 1.535A5.213 5.213 0 0 0 5 15.75h2.25a2.25 2.25 0 1 0 4.5 0h1.5a2.25 2.25 0 1 0 4.5 0H19c0-1.422-.578-2.71-1.514-3.67-.78-.778-1.745-1.32-2.824-1.533a2.741 2.741 0 0 0 .962-2.064C14.25 6.345 13.155 5.25 11.732 5.25zM12 17.25c-.414 0-.75.336-.75.75s.336.75.75.75.75-.336.75-.75-.336-.75-.75-.75z"/>
            </svg>
          </a>
    </li>
    </ul>
  </nav>
</header>

<main class="content">


<h1>Medium and HuggingFace Blogs</h1>

<p>Lists of my machine learning blogs, which I write seasonally:</p>


<section class="projects">
	<article class="project-review">
      <time class="project_date" datetime="2024-24-6T19:41:57&#43;07:00">
          June 24, 2024
      </time>
      <h3><a href="https://medium.com/@Esmail_A.Gumaan/build-your-own-llms-server-56e15ac26b3f"> Build your own llms server.</a></h3>
      <!-- <p>The fastest and most efficient repository for fine-tuning GPTs, implementing various PEFT techniques like LoRA and adapters, as well as quantization, FlashAttention, and sentiment analysis using PPO. omniGPT is an ambitious project aimed at building a GPT (Generative Pre-trained Transformer) model from scratch in Python, complemented by state-of-the-art fine-tuning techniques and optimized for performance with CUDA. This project encompasses everything from tokenization to model training, making it a robust toolkit for developing and fine-tuning large language models.</p> -->
    </article>
    <article class="project-review">
      <time class="project_date" datetime="2024-12-6T19:41:57&#43;07:00">
          June 12, 2024
      </time>
      <h3><a href="https://medium.com/@Esmail_A.Gumaan/implementation-ai-research-papers-741bf5ba9d46?source=user_profile---------3----------------------------"> How to implement AI research paper.</a></h3>
      <!-- <p>The fastest and most efficient repository for fine-tuning GPTs, implementing various PEFT techniques like LoRA and adapters, as well as quantization, FlashAttention, and sentiment analysis using PPO. omniGPT is an ambitious project aimed at building a GPT (Generative Pre-trained Transformer) model from scratch in Python, complemented by state-of-the-art fine-tuning techniques and optimized for performance with CUDA. This project encompasses everything from tokenization to model training, making it a robust toolkit for developing and fine-tuning large language models.</p> -->
    </article>
	<article class="project-review">
      <time class="project_date" datetime="2023-10-5T19:41:57&#43;07:00">
          Oct 5, 2023
      </time>
      <h3><a href="https://medium.com/@Esmail_A.Gumaan/deep-learning-and-neural-networks-46e0895792aa?source=user_profile---------0----------------------------"> Deep Learning and Neural Networks</a></h3>
      <!-- <p>The fastest and most efficient repository for fine-tuning GPTs, implementing various PEFT techniques like LoRA and adapters, as well as quantization, FlashAttention, and sentiment analysis using PPO. omniGPT is an ambitious project aimed at building a GPT (Generative Pre-trained Transformer) model from scratch in Python, complemented by state-of-the-art fine-tuning techniques and optimized for performance with CUDA. This project encompasses everything from tokenization to model training, making it a robust toolkit for developing and fine-tuning large language models.</p> -->
    </article>
  <article class="project-review">
      <time class="project_date" datetime="2023-10-27T00:00:00Z">
          Oct 27, 2023
      </time>
      <h3><a href="https://medium.com/@Esmail_A.Gumaan/neural-network-architectures-db83f41c802c?source=user_profile---------1----------------------------">Neural Network architectures</a></h3>
      <!-- <p>Welcome to Axon: AI Research Lab! This repository serves as a collaborative platform for implementing cutting-edge AI research papers and conducting novel research in various areas of artificial intelligence. Our mission is to bridge the gap between theoretical research and practical applications by providing high-quality, reproducible implementations of seminal and contemporary AI papers: InstructGPT, llama, transformers, diffusion models, RLHF, etc...</p> -->
  </article>
  <article class="project-review">
    <time class="project_date" datetime="2023-11-2T00:00:00Z">
        Nov 2, 2023
    </time>
    <h3><a href="https://medium.com/@Esmail_A.Gumaan/neural-network-activation-functions-d0a99b5173b9?source=user_profile---------2----------------------------">Neural Network activation functions.</a></h3>
    <!-- <p>X-Llama is an advanced language model framework, inspired by the original Llama model but enhanced with additional features such as Grouped Query Attention (GQA), Multi-Head Attention (MHA), and more. This project aims to provide a flexible and extensible platform for experimenting with various attention mechanisms and building state-of-the-art natural language processing models</p> -->
</article>
  <article class="project-review">
      <time class="project_date" datetime="2023-11-18T13:04:46&#43;07:00">
          Nov 18, 2023
      </time>
      <h3><a href="https://medium.com/@Esmail_A.Gumaan/importance-of-gpus-in-machine-learning-ac605c2ad198?source=user_profile---------4----------------------------">Importance of GPUs in machine learning.</a></h3>
      <!-- <p>LlTRA stands for: Language to Language Transformer model from the paper "Attention is all you Need", building transformer model:Transformer model from scratch and using it for translation using pytorch, Develop a specialized language-to-language transformer model that accurately translates from the Arabic language to the English language, ensuring semantic fidelity, contextual awareness, cross-lingual adaptability, and the retention of grammar and style. The model should provide efficient training and inference processes to make it practical and accessible for a wide range of applications, ultimately contributing to the advancement of Arabic-to-English language translation capabilities.</p> -->
  </article>
  <article class="project-review">
      <time class="project_date" datetime="2024-04-22T00:00:00Z">
          April 22, 2024
      </time>
      <h3><a href="https://huggingface.co/blog/Esmail-AGumaan/diffusion-models#diffusion-models">Diffusion Models</a></h3>
      <!-- <p>I developed a Python library for transformers, leveraging the architecture I previously designed. With this library, users can freely install and utilize the transformer architecture.</p> -->
  </article>
  <article class="project-review">
      <time class="project_date" datetime="2023-04-29T19:08:00&#43;07:00">
          April 29, 2024
      </time>
      <h3><a href="https://huggingface.co/blog/Esmail-AGumaan/attention-is-all-you-need#transformers"> Transformers.</a></h3>
      <!-- <p>Neural Network From Scratch using Java and processing environment. Brain is a neural network simulator tool implemented in Java using the Processing environment. The project aims to provide a visual representation of the decision-making process of a neural network controlling the movements of a snake. The tool incorporates a genetic algorithm to optimize the neural network's performance. Through real-time visualization, users can gain insights into the neural network's behavior, identify patterns, and witness the improvement achieved through the genetic algorithm.</p> -->
  
      <!-- </article>
  <article class="project-review">
      <time class="project_date" datetime="2023-06-19T00:00:00Z">
          June 19, 2023
      </time>
      <h3><a href="/blog/no-analytics/">Why I Stopped Using Analytics on My Website</a></h3>
  </article>
  <article class="project-review">
      <time class="project_date" datetime="2023-06-08T00:00:00Z">
          June 8, 2023
      </time>
      <h3><a href="/blog/new-website/">Welcome to My ‚ÄúNew‚Äù Website</a></h3>
  </article>
  <article class="project-review">
      <time class="project_date" datetime="2022-11-15T00:00:00Z">
          November 15, 2022
      </time>
      <h3><a href="/blog/mastodon/">Why I Will Never Join Mastodon (or the rest of the Fediverse)</a></h3>
  </article>
   -->
</section>

<!-- <p class="vault">Do you dare to enter <a href="/vault">the vault</a>? üîí</p> -->

</main>

<footer class="site-footer">
    <p><a href="/uncopyright">Uncopyrighted</a> by Esmail Gumaan. Last built March 6th, 2024.</p>
    <!-- <p>Built with <a href="https://gohugo.io" target="_blank" rel="noopener noreferrer">Hugo</a>. View the source code <a href="https://github.com/ericmurphyxyz/ericmurphy.xyz" target="_blank" rel="noopener noreferrer">on GitHub</a>.</p> -->

    <ul class="menu menu-social">
      <li>
        <a href="https://github.com/Esmail-ibraheem" target="_blank" rel="noopener noreferrer">
          <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" ><title>GitHub</title><path fill='currentColor' d="M12.001 2C6.47598 2 2.00098 6.475 2.00098 12C2.00098 16.425 4.86348 20.1625 8.83848 21.4875C9.33848 21.575 9.52598 21.275 9.52598 21.0125C9.52598 20.775 9.51348 19.9875 9.51348 19.15C7.00098 19.6125 6.35098 18.5375 6.15098 17.975C6.03848 17.6875 5.55098 16.8 5.12598 16.5625C4.77598 16.375 4.27598 15.9125 5.11348 15.9C5.90098 15.8875 6.46348 16.625 6.65098 16.925C7.55098 18.4375 8.98848 18.0125 9.56348 17.75C9.65098 17.1 9.91348 16.6625 10.201 16.4125C7.97598 16.1625 5.65098 15.3 5.65098 11.475C5.65098 10.3875 6.03848 9.4875 6.67598 8.7875C6.57598 8.5375 6.22598 7.5125 6.77598 6.1375C6.77598 6.1375 7.61348 5.875 9.52598 7.1625C10.326 6.9375 11.176 6.825 12.026 6.825C12.876 6.825 13.726 6.9375 14.526 7.1625C16.4385 5.8625 17.276 6.1375 17.276 6.1375C17.826 7.5125 17.476 8.5375 17.376 8.7875C18.0135 9.4875 18.401 10.375 18.401 11.475C18.401 15.3125 16.0635 16.1625 13.8385 16.4125C14.201 16.725 14.5135 17.325 14.5135 18.2625C14.5135 19.6 14.501 20.675 14.501 21.0125C14.501 21.275 14.6885 21.5875 15.1885 21.4875C19.259 20.1133 21.9999 16.2963 22.001 12C22.001 6.475 17.526 2 12.001 2Z"></path></svg>

        </a>
      </li><li>
        <a href="http://linkedin.com/in/esmail-a-gumaan" target="_blank" rel="noopener noreferrer">
            <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
              <title>LinkedIn</title>
              <path fill="currentColor" d="M20.447 20.452h-3.554v-5.569c0-1.328-.026-3.038-1.855-3.038-1.857 0-2.141 1.45-2.141 2.947v5.66H9.341V9h3.413v1.561h.049c.476-.9 1.636-1.848 3.368-1.848 3.599 0 4.262 2.367 4.262 5.452v6.287h-.001zM5.337 7.433c-1.144 0-2.07-.927-2.07-2.07 0-1.144.927-2.07 2.07-2.07s2.07.926 2.07 2.07c0 1.143-.926 2.07-2.07 2.07zm1.777 13.019H3.561V9h3.553v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.737v20.527C0 23.226.792 24 1.771 24h20.451c.979 0 1.771-.774 1.771-1.736V1.737C23.996.774 23.204 0 22.225 0z"></path>
            </svg>
          </a>
      </li><li>
        <a href="mailto:esm.agmaan@gmail.com" target="_blank" rel="noopener noreferrer">
          <svg role="img" width="28" height="28" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" ><title>RSS Feed</title><path fill='currentColor' d="M3 3C12.9411 3 21 11.0589 21 21H18C18 12.7157 11.2843 6 3 6V3ZM3 10C9.07513 10 14 14.9249 14 21H11C11 16.5817 7.41828 13 3 13V10ZM3 17C5.20914 17 7 18.7909 7 21H3V17Z"></path></svg>

        </a>
      </li>
    </ul>
</footer>

</body>
</html>


